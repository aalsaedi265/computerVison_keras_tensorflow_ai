{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f3d8d-419d-4b57-9da5-a188cb22229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelme got isolating target in image\n",
    "!pip install labelme  tensorflow opencv-python matplotlib albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a3172-63f4-4788-be2f-d7f51ebfacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967c238-39d2-4072-9cf2-9c6e9040a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install labelme  tensorflow opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886e3bc-930e-440f-86ff-4e32af03224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid #creates unique identifier, for filenames\n",
    "import cv2 #works with files and cameras/ audio to allow computer vison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d9933-6fa4-41c7-b79c-df50bf35b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH= os.path.join('data','images')\n",
    "number_images=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d66ab-cb99-4fb7-bb5a-1e860bf6465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621e6ee-e278-4f17-be4c-4fa6042e12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes the box for the face, this should be in label\n",
    "#this take pick put recantgle on face and save it\n",
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387bde7-df96-4af4-b062-52bab052a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bf62a-25d1-404c-b67e-8d99a3510562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # did not set up here\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04360aa2-ff68-49c8-bebb-5347b67f221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU') #test if gpu is avaliblile for dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc0155-c07e-4619-991d-f61464676493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use shuffle=False if error occurs, used inside list_files()\n",
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0e8b3-5c5d-46a2-878c-55f21941334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if images are being access\n",
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df8534-b8ab-4c27-ba43-b5273b4933b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded3299-0df3-46a6-9d6e-97b4380457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51350a1-58c2-467b-a1b1-030ca1314dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c077b7-1317-4fdf-b670-0fd7e312e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511ee1b-96f0-4da5-9ec3-e354cd45f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf4904-d401-49c7-acd8-a2c52a8eb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e91ddd-caed-44d3-a5e1-80ecbb5e8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ee0a0-4de5-4cdc-960b-5177a64ea771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dara partitionsed\n",
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a6178-c5a4-42b4-863a-05e20cb1dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab415524-f564-49ed-a9c7-2bc386934f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c839e82-31d7-4454-bf43-1f37f073ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('data','train', 'images','81e38627-0e08-11ee-8d5b-50c2e8532202.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80096f84-e0f7-4cbe-bdf6-a5e7ee4dd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', '81e38627-0e08-11ee-8d5b-50c2e8532202.json'), 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a5dc7b8-e043-455f-a3bd-ed488fd1ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[415.7317073170732, 43.65853658536585],\n",
       " [168.17073170731712, 326.5853658536585]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63a63e62-d791-463f-b47d-20972ebd26a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[415.7317073170732, 43.65853658536585],\n",
       " [168.17073170731712, 326.5853658536585]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08ff1a14-dc69-4b40-b2d2-be0e7ac3bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [0,0,0,0]\n",
    "coords[0] = label['shapes'][0]['points'][0][0]\n",
    "coords[1] = label['shapes'][0]['points'][0][1]\n",
    "coords[2] = label['shapes'][0]['points'][1][0]\n",
    "coords[3] = label['shapes'][0]['points'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "065c32d5-6410-4f35-b7f5-bf5a51eadf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[168.17073170731712, 43.65853658536585, 415.7317073170732, 326.5853658536585]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min = 168.17073170731712\n",
    "x_max = 415.7317073170732\n",
    "y_min = 43.65853658536585\n",
    "y_max = 326.5853658536585\n",
    "\n",
    "# Swap the values if x_max <= x_min\n",
    "if x_max <= x_min:\n",
    "    temp = x_max\n",
    "    x_max = x_min\n",
    "    x_min = temp\n",
    "\n",
    "coords = [x_min, y_min, x_max, y_max]\n",
    "#needed fixing becase the max ans min were swapeed, so had to reswap them\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13a8f246-cf44-4ac0-a412-117a94fc71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(np.divide(coords, [640,480,640,480])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5183fb4d-1be5-471a-b0dd-bd53c836d86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.262766768292683,\n",
       " 0.09095528455284553,\n",
       " 0.6495807926829269,\n",
       " 0.6803861788617885]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0358db59-4c49-4745-9969-9fe53529ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d64da9fb-d2de-44f2-92b4-f3238082f7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6949593495934959, 0.6968563685636856)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['bboxes'][0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7da19e32-794e-4fbd-a36c-994243d62c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1448238482384824,\n",
       "  0.06813008130081301,\n",
       "  0.6949593495934959,\n",
       "  0.6968563685636856)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a75ea-ac25-4b04-8f55-57e19cb5a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(augmented['image'], \n",
    "              tuple(np.multiply(augmented['bboxes'][0][:2], [450,450]).astype(int)),\n",
    "              tuple(np.multiply(augmented['bboxes'][0][2:], [450,450]).astype(int)), \n",
    "                    (255,0,0), 2)\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b73b8a-59f9-4762-a3d9-abfc6f89197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(60):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480fb3e-30ce-4e2e-b30c-0bb720c8dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8e971-7aa3-4836-a293-850b5fc73199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85ab26-1e7e-487d-8064-1b88c7913607",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2761cf2-13b7-49f3-b9ce-44a192f35f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ec221-7ac3-486f-b8aa-a9be56e754ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0516d2-89f2-453a-9418-c9dbfe759bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c583509-ada0-41e7-9f8f-6ddc53aa4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37961447-76ee-4b3a-9bdc-959208cae32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc022da-14c7-4570-9b90-111b5e5317ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bd279-6cfd-45d9-8610-b8b1b5cf4f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73108d07-bd96-43d1-a951-3683ed8e900d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d5013-32aa-42ee-adb2-1ea0da1eff10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68aafc-e4d8-4da5-b822-70549bfa9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "face_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
